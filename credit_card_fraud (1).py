# -*- coding: utf-8 -*-
"""credit_card_fraud.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MHb1OHv4snp2ZUZ4KuXTEOw1aFUIROXX
"""

import pandas as pd
import kagglehub
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")

print("Path to dataset files:", path)

# Loading data
df = pd.read_csv(path + "/creditcard.csv")

# Separating features and target
X = df.drop('Class', axis=1)
y = df['Class']

# Scaling the 'Amount' column
scaler = StandardScaler()
X['Amount'] = scaler.fit_transform(X[['Amount']])

# Handling class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Splitting data
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Defining model
model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compiling model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Trainnig model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

from sklearn.metrics import classification_report

# Predictions on test data
y_pred = (model.predict(X_test) > 0.5).astype("int32")

# Print evaluation metrics
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Train loss')
plt.plot(history.history['val_loss'], label='Validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()